skel_full = read.csv("/Users/hannahaichelman/Documents/BU/TVE/SkeletonMorphometry/skel_phys_full.csv")
str(t0_full)
t0_full$sitename <- as.factor(t0_full$sitename)
t0_full$treat <- as.factor(t0_full$treat)
t0_full$lineage <- as.factor(t0_full$lineage)
str(end_full)
end_full$sitename <- as.factor(end_full$sitename)
end_full$treat <- as.factor(end_full$treat)
end_full$lineage <- as.factor(end_full$lineage)
str(skel_full)
skel_full$sitename <- as.factor(skel_full$sitename)
skel_full$treat <- as.factor(skel_full$treat)
skel_full$lineage <- as.factor(skel_full$lineage)
# add in dominant symbiont type dataframe
its2_types = read.csv("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/ITS2.dominanttype.csv") %>%
select(frag, dominant_type) %>%
mutate(dominant_type = as.factor(dominant_type))
end_full_its2 <- left_join(end_full, its2_types, by = "frag")
str(end_full_its2)
# Dont want to use log transformed data here
# but need to remove NAs
t0_full_adonis = t0_full %>%
dplyr::filter(complete.cases(.)) %>% #drop any row that has an NA for any time point
dplyr::filter(lineage != "L3") %>% # remove L3 individuals since these aren't in our PCAs
select(-corallite.avg.poly.mm2) # removing here because it is now included in the skeleton morphology pca (revision)
end_full_adonis = end_full_its2 %>%
dplyr::filter(complete.cases(.)) %>% #drop any row that has an NA for any time point
mutate(T3_T0_rgr_2 = T3_T0_rgr + 2) %>%
select(-T3_T0_rgr) %>% #get rid of the column with negative growth values before log transforming, just making sure to use the same data as we do in the PCAs
dplyr::filter(lineage != "L3") # remove L3 individuals since these aren't in our PCAs
skel_full_adonis = skel_full %>%
dplyr::filter(complete.cases(.)) %>% #drop any row that has an NA for any time point
dplyr::filter(lineage != "L3") # remove L3 individuals since these aren't in our PCAs
end_full_adonis <- end_full_adonis[, c(1,2,3,4,11,5,6,7,8,9,10,12)]
end_full_adonis_L1 = end_full_adonis %>%
filter(lineage == "L1")
end_full_adonis_L2 = end_full_adonis %>%
filter(lineage == "L2")
# Change dataframe here based on the comparison you are interested in
#nl=startedLog(data=end_full_adonis,count.columns=6:12, logstart=1)
nl=startedLog(data=t0_full_adonis,count.columns=5:10, logstart=1)
goods.dist=vegdist(nl, method="bray", na.rm = TRUE)
goods.pcoa=pcoa(goods.dist)
# PCA:
pcp=prcomp(nl, retx=TRUE, center=TRUE)
scores=goods.pcoa$vectors
summary(goods.pcoa)
#conditions=end_full_adonis[, c("frag","treat","sitename","lineage","dominant_type")] #make sure to change dataframe here
conditions=t0_full_adonis[, c("frag","treat","sitename","lineage")] #make sure to change dataframe here
# PERMANOVA
head(scores)
head(conditions)
t0_model = adonis(scores~lineage, data=conditions, method="euclidean", permutations = 10000)
t0_output = adonis_OmegaSq(t0_model, partial = TRUE)
t0_output$aov.tab
# Change dataframe here based on the comparison you are interested in
nl=startedLog(data=end_full_adonis,count.columns=6:12, logstart=1)
goods.dist=vegdist(nl, method="bray", na.rm = TRUE)
goods.pcoa=pcoa(goods.dist)
# PCA:
pcp=prcomp(nl, retx=TRUE, center=TRUE)
scores=goods.pcoa$vectors
summary(goods.pcoa)
conditions=end_full_adonis[, c("frag","treat","sitename","lineage","dominant_type")] #make sure to change dataframe here
# PERMANOVA
head(scores)
head(conditions)
end_model = adonis(scores~lineage+dominant_type+treat, data=conditions, method="euclidean", permutations = 10000)
install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
library(devtools)
install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
library(pairwiseAdonis)
pairwise.adonis(end_output)
pairwise.adonis(end_output, factors = treat)
pairwise.adonis(end_model, factors = treat)
pairwise.adonis(end_model, factors = conditions$treat)
iris
head(iris)
data("iris")
pairwise.adonis(scores, conditions$treat)
pairwise.adonis(scores, conditions$lineage)
scores
View(scores)
install.packages("EcolUtils")
# Change dataframe here based on the comparison you are interested in
nl=startedLog(data=end_full_adonis,count.columns=6:12, logstart=1)
goods.dist=vegdist(nl, method="bray", na.rm = TRUE)
goods.pcoa=pcoa(goods.dist)
# PCA:
pcp=prcomp(nl, retx=TRUE, center=TRUE)
scores=goods.pcoa$vectors
summary(goods.pcoa)
conditions=end_full_adonis[, c("frag","treat","sitename","lineage","dominant_type")] #make sure to change dataframe here
# PERMANOVA
head(scores)
head(conditions)
end_model = adonis(scores~lineage+dominant_type+treat, data=conditions, method="euclidean", permutations = 10000)
end_output = adonis_OmegaSq(end_model, partial = TRUE)
end_output$aov.tab
pairwise.adonis(scores, conditions$treat)
head(end_full_adonis)
pairwise.adonis(end_full_adonis[,6:12], end_full_adonis$treat)
pairwise.adonis(end_full_adonis[,6:12], end_full_adonis$lineage)
citation()
library(shiny)
library(plotly)
library(plyr)
library(dplyr)
library(reshape2)
library(tidyr)
library(ggplot2)
library(xts)
library(zoo)
library(TTR)
library(scales)
library(ggpubr)
library(signal)
library(data.table)
library(ggridges)
library(Rmisc)
cols_site <- c("CI" = "#543005", "PD"= "#bf812d",  "SP"= "#dfc27d",  "BN" = "#003c30", "BS"= "#35978f", "CA"= "#80cdc1")
cols_treat <- c("darkgrey", "#FF9966","#CC3300","#7f0000")
cols_lineage <- c("L1" = "#3f007d", "L2" = "#807dba", "L3" = "#bcbddc")
its2_cols_greens = c("C1" = "#edf8e9", "C3af" = "#238b45","C3" = "#a1d99b","D1" = "#00441b")
# set wd
setwd("/Users/hannahaichelman/Documents/BU/TVE/TemperatureData/Field_Hobo_Loggers/Trimmed HOBO txt files")
# what's in the wd
list.files("/Users/hannahaichelman/Documents/BU/TVE/TemperatureData/Field_Hobo_Loggers/Trimmed HOBO txt files")
# read in this csv to skip running this section of code
daily.mmm <- read.csv(file = "/Users/hannahaichelman/Documents/BU/TVE/TemperatureData/Field_Hobo_Loggers/data_sheets/DailyTempRangeData.csv")
daily.mmm = daily.mmm %>%
dplyr::filter(logger!="Drago.OR4")
# rank sites by daily variability overall
aggregate(range ~ logger, data = daily.mmm, FUN = "mean")
aggregate(range ~ logger, data = daily.mmm, FUN = "max")
aggregate(max ~ logger, data = daily.mmm, FUN = "max")
summarySE(data = daily.mmm, groupvar = "logger", measurevar = "mean")
# daily range as boxplot
dtv_boxplot <- ggplot(daily.mmm.plot, aes(x=logger, y=range)) +
geom_jitter(shape=16,
position=position_jitter(0.2),
alpha=0.99,
aes(color = logger)) +
scale_color_manual(values = cols_site) + # for jittered points
geom_boxplot(outlier.shape = NA,
alpha = 0.85,
aes(fill = logger))+
scale_fill_manual(values = cols_site) + # for boxplot
ylab("Daily Temperature Range (°C)") +
xlab("Site") +
#ylim(0,3.2) +
theme(axis.text.x = element_text(angle = 45, vjust=0.7, hjust=.6)) +
theme_bw() +
theme(legend.position = "none")
dtv_boxplot
#### Figure 1 Boxplots ####
daily.mmm$logger = as.factor(daily.mmm$logger)
daily.mmm.plot = daily.mmm %>%
dplyr::filter(logger != "Drago.OR4")
daily.mmm.plot$logger = droplevels(daily.mmm.plot$logger)
str(daily.mmm.plot)
daily.mmm.plot$logger = factor(daily.mmm.plot$logger, levels = c("Punta.IR1", "STRI.IR2", "Cristo.IR3.arr1", "Cayo.OR3.arr3"))
levels(daily.mmm.plot$logger) <- c("PD", "SP", "CI", "CA") # double check this
daily.mmm.plot$logger <- factor(daily.mmm.plot$logger, levels = c("PD", "SP", "CI", "CA"))
mean_boxplot <- ggplot(daily.mmm.plot, aes(x=logger, y=mean)) +
geom_jitter(shape=16,
position=position_jitter(0.2),
alpha=0.99,
aes(color = logger)) +
scale_color_manual(values = cols_site) + # for jittered points
geom_boxplot(outlier.shape = NA,
alpha = 0.85,
aes(fill = logger))+
scale_fill_manual(values = cols_site) + # for boxplot
ylab("Daily Mean Temperature (°C)") +
xlab("Site") +
theme(axis.text.x = element_text(angle = 45, vjust=0.7, hjust=.6)) +
theme_bw() +
theme(legend.position = "none")
mean_boxplot
library(plyr)
library(dplyr)
library(tidyverse)
library(vegan)
setwd("/Users/hannahaichelman/Documents/BU/TVE/2bRAD/Analysis/")
bams=data.frame(read.table("tuftscustompipeline_denovo_nosyms/bams.txt", header=FALSE)) # list of bam files
colnames(bams)<- "bam"
# loading individual to population correspondences
i2p=read.table("bam_barcode_names_tuftscustom.csv",sep=",",header=TRUE) # 2-column tab-delimited table of individual assignments to populations; must be in the same order as samples in the bam list or vcf file.
row.names(i2p)=i2p[,1]
#i2p=i2p[goods,]
site=i2p[,2]
# add in site name
i2p$sitename <- ifelse(i2p$pop == 'I2', 'SP',
ifelse(i2p$pop == 'I3', 'CI',
ifelse(i2p$pop == 'I4', 'PD',
ifelse(i2p$pop == 'O2', 'BS',
ifelse(i2p$pop == 'O3', 'CA',
'BN')))))
# create new data frame using i2p without clones (duplicated preps), but still with two actual clones (I4G + I4F)
# this is removing files that have the lower coverage/fewer reads
i2p_noclones_allsamps = i2p %>%
dplyr::filter(bam != "4-MullenDavies_S4_TCAC.nosymbio.fastq.bam") %>% # O4E
dplyr::filter(bam != "1-MullenDavies_S1_GCTT.nosymbio.fastq.bam") %>% # O2A
dplyr::filter(prepped_id != "I4A_CLONE") %>% # I4A
dplyr::filter(bam != "2-MullenDavies_S2_AGTG.nosymbio.fastq.bam") %>% # O4A
dplyr::filter(bam != "3-MullenDavies_S3_TGGT.nosymbio.fastq.bam") %>% # I3H
dplyr::filter(prepped_id != "O3B_CLONE") %>% # O3B
dplyr::filter(bam != "4-MullenDavies_S4_TCAG.nosymbio.fastq.bam") %>% # O2E
dplyr::filter(bam != "1-MullenDavies_S1_TGGT.nosymbio.fastq.bam") %>% # I2E sample 1
dplyr::filter(bam != "5-MullenDavies_S5_TGGT.nosymbio.fastq.bam") %>% # I2E sample 2
dplyr::filter(bam != "1-MullenDavies_S1_ACCA.nosymbio.fastq.bam") # I3C
# make a new bams file with this filtered i2p file and write out a csv file
bams_noclones_allsamps = i2p_noclones_allsamps %>%
select(bam)
# Remove I4G so this is actually no clones here - I4G was a smaller bam file
i2p_noclones = i2p_noclones_allsamps %>%
dplyr::filter(bam != "1-MullenDavies_S1_GTGA.nosymbio.fastq.bam") # I4G
# make new bams file for this filtered i2p file with no clones at all
bams_noclones = i2p_noclones %>%
select(bam)
site=i2p_noclones[,8]
cols_site <- c("CI" = "#543005", "PD"= "#bf812d",  "SP"= "#dfc27d",  "BN" = "#003c30", "BS"= "#35978f", "CA"= "#80cdc1")
cols_treat <- c("darkgrey", "#FF9966","#CC3300","#7f0000")
cols_lineage <- c("#bcbddc","#756bb1")
#-------------
# clustering / PCoA based on identity by state (IBS) based on single read resampling
# (for low and/or uneven coverage)
# all clones removed
ma = as.matrix(read.table("tuftscustompipeline_denovo_nosyms/myresult2.noclone.ibsMat"))
colnames(ma)=i2p_noclones$sample_id
rownames(ma)=i2p_noclones$sample_id
hc=hclust(as.dist(ma),"ave")
plot(hc,cex=0.5)  # this shows how similar clones are
abline(h=0.265, lwd = 2, lty = 2, col = "grey")
# performing PCoA and CAP
conds=data.frame(cbind(site))
pp0=capscale(ma~1)
pp=capscale(ma~site,conds)
# significance of by-site divergence
adonis2(ma~site,conds)
# eigenvectors
plot(pp0$CA$eig)
# find % variance explained - eigenvector for MDS1 / sum of remaining eigenvectors
eigs = as.data.frame(pp0$CA$eig)
eigs$MDS = rownames(eigs)
head(eigs)
# % variance explained by MDS1 = 26.7% variance
eigs[1,1]/sum(eigs[2:49, 1])
# % variance explained by MDS2 = 3.9% variance explained
eigs[2,1]/sum(eigs[3:49, 1])
axes2plot=c(1,2)
library(adegenet) # for transp()
cmd=pp0
plot(cmd,choices=axes2plot,display="sites",type="n") # choices - axes to display
points(cmd,choices=axes2plot,pch=19,col=transp(colors,alpha=0.7))
pca_s <- as.data.frame(cmd$CA$u[,axes2plot])
#colors=c('royalblue4','cornflowerblue','lightblue','red4','indianred3','mistyrose3')
cols_site <- c("CI" = "#543005", "PD"= "#bf812d",  "SP"= "#dfc27d",  "BN" = "#003c30", "BS"= "#35978f", "CA"= "#80cdc1")
MDS1_2 = ggplot(pca_s, aes(MDS1, MDS2)) +
theme_bw() +
geom_point(aes(colour=conds$site, shape =conds$site), size=2, stroke = 1)  +
stat_ellipse(type = "t",
aes(color = conds$site), show.legend = NA, lwd = 1) +
scale_color_manual(values=cols_site,
breaks = c("BN", "BS", "CA", "CI", "PD", "SP"),
name = "Site") +
scale_shape_manual(values = c(15,16,17,22,21,24),
breaks = c("BN", "BS", "CA", "CI", "PD", "SP"),
name = "Site") +
xlab("MDS1 (26.7% explained variance)") +
ylab("MDS2 (3.9% explained variance)")
MDS1_2
pca_s
View(pca_s)
dim(pca_s)
library(decontam)
packageVersion("decontam") #‘1.10.0’ - NK's version - 1.16.0 HA's version
library(phyloseq)
library(tidyverse)
library(ggpubr)
library(dplyr)
library(viridis)
# SymPortal ITS2 DIV Analysis
# cleaned file up to remove extraneous info in the header in excel, but original file here:
# /Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles/154_20210426_DBV_20210427T024417.profiles.absolute.abund_and_meta.txt
setwd("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles")
its2_prestress = read.csv("SymPortal_PreStress_RawDIVs.csv")
head(its2_prestress)
#### PS Object Versions ####
ps.cleanest = readRDS("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/ps.its2.RDS")
seqtab <- data.frame(ps.cleanest@otu_table)
samdf <- data.frame(ps.cleanest@sam_data)
ps.cleanest.rel = readRDS("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/ps.its2.rel.RDS")
seqtab.rel <- data.frame(ps.cleanest.rel@otu_table)
samdf.rel <- data.frame(ps.cleanest.rel@sam_data)
taxa = read.csv(file = "/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/symportal_taxa.csv", header = TRUE) %>%
select(-X)
rownames(taxa) <- as.factor(taxa$DIV)
sum(taxa$genus == "B") # 2 div
sum(taxa$genus == "C") # 13 div
sum(taxa$genus == "D") # 5 div
mtaxa <- as.matrix(taxa)
#### Bar plot - post-processing ####
#its2_cols_end = c("#D53E4F", "#F46D43", "#3288BD", "#FEE08B", "#E6F598", "#ABDDA4", "#66C2A5", "#3288BD", "#FDAE61")
#its2_cols_purple = c("white", "#efedf5","#bcbddc", "#756bb1")
its2_cols_greens = c("B19" = "#ffeda0", "B5" = "#fd8d3c",
"C1" = "#edf8e9", "C15" = "#feb24c",  "C3" = "#a1d99b",
"C3af" = "#238b45", "D1" = "#00441b")
its2_cols_blues = c("#f6eff7", "#d0d1e6", "#a6bddb", "#67a9cf", "#3690c0", "#02818a", "#016450")
plot_bar(ps.cleanest.rel, x="frag", fill="majority_its2") +
theme_bw()
# Lineage:
ps.lin <- merge_samples(ps.cleanest, "lineage")
ps.rel.lin <- transform_sample_counts(ps.lin, function(x) x / sum(x))
p.lineage = plot_bar(ps.rel.lin, fill="majority_its2") +
geom_bar(stat = "identity") +
scale_fill_manual(name = "Majority ITS2", values = its2_cols_greens) +
theme_bw()
p.lineage
ps.rel.lin
ps.lin
View(ps.cleanest)
View(ps.cleanest@sam_data)
dim(ps.cleanest@sam_data)
ps.cleanest@sam_data==L2
as.data.frame(ps.cleanest@sam_data)
df = as.data.frame(ps.cleanest@sam_data)
dim(df)
df %>% subset(lineage=="L2")
df %>% subset(lineage=="L2") %>% sum()
dim(df %>% subset(lineage=="L2"))
dim(df %>% subset(lineage=="L1"))
library(ggplot2)
library(lme4)
library(plotly)
library(ggridges)
library(tidyverse)
library(arsenal) #easily compare two data frames
library(Rmisc)
library(lmerTest)
library(emmeans)
library(reshape)
library(readxl)
library(wesanderson)
library(ggpubr)
library(car)
library(sjPlot)
library(effects)
library(glmmTMB)
library(performance)
library(patchwork)
library(magrittr)
library(SciViews)
#### Skeleton Morphometrics and DLI ####
skel_phys = read.csv("/Users/hannahaichelman/Documents/BU/TVE/SkeletonMorphometry/T0_morphology.csv")
head(skel_phys)
str(skel_phys)
skel_phys2 = skel_phys %>%
mutate(treat = as.factor(treat), sitename = as.factor(sitename), reef = as.factor(reef), lineage = as.factor(lineage))
head(skel_phys2)
#create a new column of combined genotype and site for stats later
skel_phys2$origsitecode <- substr(skel_phys2$frag, 1, 2)
skel_phys2$genet <- substr(skel_phys2$frag,3,3)
skel_phys3 = skel_phys2 %>%
unite(gen_site, c(origsitecode,genet), sep = "", remove = FALSE) %>%
mutate(gen_site = as.factor(gen_site)) %>%
dplyr::filter(gen_site != "I4G") # clone with I4F, remove from dataset
# subset data for plotting DLI and LEF
skel_phys_nona = skel_phys3 %>%
drop_na(lef)
skel_phys_CI = skel_phys_nona %>%
dplyr::filter(sitename == "CI")
skel_phys_SP = skel_phys_nona %>%
dplyr::filter(sitename == "SP")
skel_phys_nona_2lin = skel_phys_nona %>%
dplyr::filter(is.na(lineage) | lineage!="L3") # want to keep NA values for lineage here since they still have other info, will remove na's for lineage specific plots
# Stats of light enhancement factor by lineage
str(skel_phys2)
# light enhancement factor plots
# summarize data for plotting
lef_means <- summarySE(skel_phys_nona, measurevar="lef", groupvars=c("lineage"))
lef_means_2lin <- summarySE(skel_phys_nona_2lin, measurevar="lef", groupvars=c("lineage"))
lef_means_2lin
#packages
#install.packages("decontam")
library(decontam)
packageVersion("decontam") #‘1.10.0’ - NK's version - 1.16.0 HA's version
library(phyloseq)
library(tidyverse)
library(ggpubr)
library(dplyr)
library(viridis)
# SymPortal ITS2 DIV Analysis
# cleaned file up to remove extraneous info in the header in excel, but original file here:
# /Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles/154_20210426_DBV_20210427T024417.profiles.absolute.abund_and_meta.txt
setwd("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles")
# SymPortal ITS2 DIV Analysis
# cleaned file up to remove extraneous info in the header in excel, but original file here:
# /Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles/154_20210426_DBV_20210427T024417.profiles.absolute.abund_and_meta.txt
setwd("/Users/hannahaichelman/Dropbox/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles")
its2_prestress = read.csv("SymPortal_PreStress_RawDIVs.csv")
head(its2_prestress)
##### Read in and format data #####
# set wd
setwd("/Users/hannahaichelman/Documents/BU/TVE")
##### Read in and format data #####
# set wd
setwd("/Users/hannahaichelman/Dropbox/BU/TVE/TVE_Github/DielTempVariability/Physiology_Data")
# read in the data
post_phys <- read.csv('data_files/dtvmaster.csv') # physiology data taken at the end of the experiment
init_phys <- read.csv('data_files/initial-phys-mod.csv') # physiology data taken at the start of the experiment
head(init_phys)
View(init_phys)
# SymPortal ITS2 DIV Analysis
# cleaned file up to remove extraneous info in the header in excel, but original file here:
# /Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles/154_20210426_DBV_20210427T024417.profiles.absolute.abund_and_meta.txt
setwd("/Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles")
# SymPortal ITS2 DIV Analysis
# cleaned file up to remove extraneous info in the header in excel, but original file here:
# /Users/hannahaichelman/Documents/BU/TVE/16S_ITS2/PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles/154_20210426_DBV_20210427T024417.profiles.absolute.abund_and_meta.txt
setwd("/Users/hannahaichelman/Dropbox/BU/TVE/16S_ITS2/ITS_PreStress_Timepoint/20210421_aichelman_PreStress/its2_type_profiles")
its2_prestress = read.csv("SymPortal_PreStress_RawDIVs.csv")
head(its2_prestress)
# Remove samples not included in this dataset
its2_prestress = its2_prestress %>%
filter(frag != "Alexa2") %>%
filter(frag != "Alexa1") %>%
filter(frag != "MA2") %>%
filter(frag != "ME1") %>%
filter(frag != "negcontrol1") %>%
filter(frag != "ITS-neg-old") %>%
filter(frag != "negcontrol2") %>%
filter(frag != "ITS-neg-new")
library(decontam)
packageVersion("decontam") #‘1.10.0’ - NK's version - 1.16.0 HA's version
library(phyloseq)
library(tidyverse)
library(ggpubr)
library(dplyr)
library(viridis)
#library(microbiomeutilities)
# Remove samples not included in this dataset
its2_prestress = its2_prestress %>%
filter(frag != "Alexa2") %>%
filter(frag != "Alexa1") %>%
filter(frag != "MA2") %>%
filter(frag != "ME1") %>%
filter(frag != "negcontrol1") %>%
filter(frag != "ITS-neg-old") %>%
filter(frag != "negcontrol2") %>%
filter(frag != "ITS-neg-new")
# Remove clades that are not symbiotic
its2_prestress2 = its2_prestress %>%
select(-contains("E1c"))
# Look for and remove DIVs with 0 reads after removing samples
colSums(its2_prestress2[,-1])
# Remove DIVs that have 0 reads
its2_prestress3 = its2_prestress2 %>%
select(-B2) %>%
select(-B1)
str(its2_prestress3)
its2_prestress3 = its2_prestress3 %>%
mutate_if(is.integer,as.numeric)
# Look for individual samples with 0 reads:
rowSums(its2_prestress3[, 2:21]) # I3H2 has 0 reads
# remove individuals with 0 reads and those in under-represented lineage 3
its2_prestress4 <- its2_prestress3 %>%
filter(frag!= "I3H2") %>% #have to remove sample I3H2 because 0 reads
filter(frag!="I2D4") %>% #lineage 3
filter(frag!="I2I7") %>% #lineage 3
filter(frag!="I2I4") %>% #lineage 3
filter(frag!="I2I3") %>% #lineage 3
filter(frag!="I2D1") %>% #lineage 3
filter(frag!="I2H13") %>% #lineage 3
filter(frag!="I2H2") %>% #lineage 3
filter(frag!="I2H12") %>% #lineage 3
filter(frag!="I2D3") %>% #lineage 3
filter(frag!="I2I10") %>% #lineage 3
filter(frag!="I2H4") %>% #lineage 3
column_to_rownames("frag")
head(its2_prestress4)
str(its2_prestress4)
# keep this df for div analysis
its2_divs = its2_prestress4
# read in sample data
# DIVs:
samdf = read.csv("SampleInfo.csv")
# add identifying data
phys_metadata = read.csv("/Users/hannahaichelman/Dropbox/BU/TVE/phys_metadata.csv") %>%
select(-dominant_type)
head(phys_metadata)
# combine with samdf
samdf = left_join(samdf, phys_metadata, by = "frag")
# remove the rows for samples that have been removed in data
samdf = samdf %>%
filter(frag != "negcontrol1") %>%
filter(frag != "ITS-neg-old") %>%
filter(frag != "negcontrol2") %>%
filter(frag != "ITS-neg-new") %>%
filter(frag != "I3H2") %>% #have to remove sample I3H2 'cause 0 reads
filter(is.na(lineage) | lineage!="L3") # remove lineage 3 from dataset but don't remove other NAs for lineage
str(samdf)
samdf$treat = as.factor(samdf$treat)
samdf$sitename = as.factor(samdf$sitename)
samdf$lineage = as.factor(samdf$lineage)
# change levels of treatment factor
samdf$treat = factor(samdf$treat,levels = c("Control","Control 2","Low Var","Mod Var","High Var"))
#rownames have to match between counts table & sample data table or else phyloseq will throw a fit
rownames(samdf) <- samdf$frag
dim(its2_divs)
dim(samdf)
